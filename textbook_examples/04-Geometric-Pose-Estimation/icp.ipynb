{"cells":[{"cell_type":"markdown","metadata":{"id":"EgiF12Hf1Dhs","colab_type":"text","cell_id":"de683597725e43b8af6e5480beb7ac45","deepnote_cell_type":"markdown"},"source":"This notebook provides examples to go along with the [textbook](http://manipulation.csail.mit.edu/pose.html).  I recommend having both windows open, side-by-side!","block_group":"4e6006baff89485e9d0f75cea8216729"},{"cell_type":"code","metadata":{"id":"eeMrMI0-1Dhu","colab":{},"colab_type":"code","cell_id":"ab66ef132c7d4b21a4aa827d9d7b9f29","deepnote_cell_type":"code"},"source":"from functools import partial\n\nimport matplotlib.animation as animation\nimport matplotlib.pyplot as plt\nimport mpld3\nimport numpy as np\nfrom IPython.display import HTML, display\nfrom pydrake.all import (\n    CsdpSolver,\n    MathematicalProgram,\n    PointCloud,\n    RigidTransform,\n    RotationMatrix,\n    Solve,\n    ge,\n)\nfrom scipy.spatial import KDTree\n\nfrom manipulation import running_as_notebook\n\nif running_as_notebook:\n    mpld3.enable_notebook()","block_group":"1a5d9c8c999e4b05b45e5b6b3ad8872c","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"cell_id":"007af87fb81d45bf8db1507813a88b66","deepnote_cell_type":"markdown"},"source":"# Point cloud registration with known correspondences","block_group":"baec6dfd299b49e7a376d0c2a06c2762"},{"cell_type":"code","metadata":{"cell_id":"c49bab620e2e4eb496af8997fa7026f6","deepnote_cell_type":"code"},"source":"def MakeRandomObjectModelAndScenePoints(\n    num_model_points=20,\n    noise_std=0,\n    num_outliers=0,\n    yaw_O=None,\n    p_O=None,\n    num_viewable_points=None,\n    seed=None,\n):\n    \"\"\"Returns p_Om, p_s\"\"\"\n    rng = np.random.default_rng(seed)\n\n    # Make a random set of points to define our object in the x,y plane\n    theta = np.arange(0, 2.0 * np.pi, 2.0 * np.pi / num_model_points)\n    l = (\n        1.0\n        + 0.5 * np.sin(2.0 * theta)\n        + 0.4 * rng.random((1, num_model_points))\n    )\n    p_Om = np.vstack((l * np.sin(theta), l * np.cos(theta), 0 * l))\n\n    # Make a random object pose if one is not specified, and apply it to get the scene points.\n    if p_O is None:\n        p_O = [2.0 * rng.random(), 2.0 * rng.random(), 0.0]\n    if len(p_O) == 2:\n        p_O.append(0.0)\n    if yaw_O is None:\n        yaw_O = 0.5 * rng.random()\n    X_O = RigidTransform(RotationMatrix.MakeZRotation(yaw_O), p_O)\n    if num_viewable_points is None:\n        num_viewable_points = num_model_points\n    assert num_viewable_points <= num_model_points\n    p_s = X_O.multiply(p_Om[:, :num_viewable_points])\n    p_s[:2, :] += rng.normal(scale=noise_std, size=(2, num_viewable_points))\n    if num_outliers:\n        outliers = rng.uniform(low=-1.5, high=3.5, size=(3, num_outliers))\n        outliers[2, :] = 0\n        p_s = np.hstack((p_s, outliers))\n\n    return p_Om, p_s, X_O\n\n\ndef MakeRectangleModelAndScenePoints(\n    num_points_per_side=7,\n    noise_std=0,\n    num_outliers=0,\n    yaw_O=None,\n    p_O=None,\n    num_viewable_points=None,\n    seed=None,\n):\n    rng = np.random.default_rng(seed)\n    if p_O is None:\n        p_O = [2.0 * rng.random(), 2.0 * rng.random(), 0.0]\n    if len(p_O) == 2:\n        p_O.append(0.0)\n    if yaw_O is None:\n        yaw_O = 0.5 * rng.random()\n    X_O = RigidTransform(RotationMatrix.MakeZRotation(yaw_O), p_O)\n    if num_viewable_points is None:\n        num_viewable_points = 4 * num_points_per_side\n\n    x = np.arange(-1, 1, 2 / num_points_per_side)\n    half_width = 2\n    half_height = 1\n    top = np.vstack((half_width * x, half_height + 0 * x))\n    right = np.vstack((half_width + 0 * x, -half_height * x))\n    bottom = np.vstack((-half_width * x, -half_height + 0 * x))\n    left = np.vstack((-half_width + 0 * x, half_height * x))\n    p_Om = np.vstack(\n        (\n            np.hstack((top, right, bottom, left)),\n            np.zeros((1, 4 * num_points_per_side)),\n        )\n    )\n    p_s = X_O.multiply(p_Om[:, :num_viewable_points])\n    p_s[:2, :] += rng.normal(scale=noise_std, size=(2, num_viewable_points))\n    if num_outliers:\n        outliers = rng.uniform(low=-1.5, high=3.5, size=(3, num_outliers))\n        outliers[2, :] = 0\n        p_s = np.hstack((p_s, outliers))\n\n    return p_Om, p_s, X_O\n\n\ndef PlotEstimate(\n    p_Om, p_s, Xhat_O=RigidTransform(), chat=None, X_O=None, ax=None\n):\n    p_m = Xhat_O.multiply(p_Om)\n    if ax is None:\n        ax = plt.subplot()\n    Nm = p_Om.shape[1]\n    artists = ax.plot(p_m[0, :], p_m[1, :], \"bo\")\n    artists += ax.fill(p_m[0, :], p_m[1, :], \"lightblue\", alpha=0.5)\n    artists += ax.plot(p_s[0, :], p_s[1, :], \"ro\")\n    if chat is not None:\n        artists += ax.plot(\n            np.vstack((p_m[0, chat], p_s[0, :])),\n            np.vstack((p_m[1, chat], p_s[1, :])),\n            \"g--\",\n        )\n    if X_O:\n        p_s = X_O.multiply(p_Om)\n    artists += ax.fill(p_s[0, :Nm], p_s[1, :Nm], \"lightsalmon\")\n    ax.axis(\"equal\")\n    return artists\n\n\ndef PrintResults(X_O, Xhat_O):\n    p = X_O.translation()\n    aa = X_O.rotation().ToAngleAxis()\n    print(f\"True position: {p}\")\n    print(f\"True orientation: {aa}\")\n    p = Xhat_O.translation()\n    aa = Xhat_O.rotation().ToAngleAxis()\n    print(f\"Estimated position: {p}\")\n    print(f\"Estimated orientation: {aa}\")\n\n\ndef PoseEstimationGivenCorrespondences(p_Om, p_s, chat):\n    \"\"\"Returns optimal X_O given the correspondences\"\"\"\n    # Apply correspondences, and transpose data to support numpy broadcasting\n    p_Omc = p_Om[:, chat].T\n    p_s = p_s.T\n\n    # Calculate the central points\n    p_Ombar = p_Omc.mean(axis=0)\n    p_sbar = p_s.mean(axis=0)\n\n    # Calculate the \"error\" terms, and form the data matrix\n    merr = p_Omc - p_Ombar\n    serr = p_s - p_sbar\n    W = np.matmul(serr.T, merr)\n\n    # Compute R\n    U, Sigma, Vt = np.linalg.svd(W)\n    R = np.matmul(U, Vt)\n    if np.linalg.det(R) < 0:\n        print(\"fixing improper rotation\")\n        Vt[-1, :] *= -1\n        R = np.matmul(U, Vt)\n\n    # Compute p\n    p = p_sbar - np.matmul(R, p_Ombar)\n\n    return RigidTransform(RotationMatrix(R), p)\n\n\np_Om, p_s, X_O = MakeRandomObjectModelAndScenePoints(num_model_points=20)\n# p_Om, p_s, X_O = MakeRectangleModelAndScenePoints()\nXhat = RigidTransform()\nc = range(p_Om.shape[1])  # perfect, known correspondences\nfig, ax = plt.subplots(1, 2)\nPlotEstimate(p_Om, p_s, Xhat, c, ax=ax[0])\nXhat = PoseEstimationGivenCorrespondences(p_Om, p_s, c)\nax[1].set_xlim(ax[0].get_xlim())\nax[1].set_ylim(ax[0].get_ylim())\nPlotEstimate(p_Om, p_s, Xhat, c, ax=ax[1])\nax[0].set_title(\"Original Data\")\nax[1].set_title(\"After Registration\")\nPrintResults(X_O, Xhat)","block_group":"02c3afaf676a4e6c826bfedbb9575f90","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AHfxMwrvb1mz","colab_type":"text","cell_id":"ae8be84523ab436381b5923a532e930a","deepnote_cell_type":"markdown"},"source":"# Iterative Closest Point (ICP)","block_group":"a768635cfbd14fc2a27f6b38388a88ae"},{"cell_type":"code","metadata":{"id":"N2cYjTpub1m0","tags":[],"colab":{},"colab_type":"code","cell_id":"87faf65326bd4900829eb42c25dda221","deepnote_cell_type":"code"},"source":"def FindClosestPoints(point_cloud_A, point_cloud_B):\n    \"\"\"\n    Finds the nearest (Euclidean) neighbor in point_cloud_B for each\n    point in point_cloud_A.\n    @param point_cloud_A A 3xN numpy array of points.\n    @param point_cloud_B A 3xN numpy array of points.\n    @return indices An (N, ) numpy array of the indices in point_cloud_B of each\n        point_cloud_A point's nearest neighbor.\n    \"\"\"\n    indices = np.empty(point_cloud_A.shape[1], dtype=int)\n\n    kdtree = KDTree(point_cloud_B.T)\n    for i in range(point_cloud_A.shape[1]):\n        distance, indices[i] = kdtree.query(point_cloud_A[:, i], k=1)\n\n    return indices\n\n\ndef IterativeClosestPoint(p_Om, p_s, X_O=None, animate=True):\n    Xhat = RigidTransform()\n    Nm = p_s.shape[1]\n    chat_previous = (\n        np.zeros(Nm) - 1\n    )  # Set chat to a value that FindClosePoints will never return.\n\n    if animate:\n        fig, ax = plt.subplots()\n        frames = []\n        frames.append(\n            PlotEstimate(\n                p_Om=p_Om, p_s=p_s, Xhat_O=Xhat, chat=None, X_O=X_O, ax=ax\n            )\n        )\n\n    while True:\n        chat = FindClosestPoints(p_s, Xhat.multiply(p_Om))\n        if np.array_equal(chat, chat_previous):\n            # Then I've converged.\n            break\n        chat_previous = chat\n        if animate:\n            frames.append(\n                PlotEstimate(\n                    p_Om=p_Om, p_s=p_s, Xhat_O=Xhat, chat=chat, X_O=X_O, ax=ax\n                )\n            )\n        Xhat = PoseEstimationGivenCorrespondences(p_Om, p_s, chat)\n        if animate:\n            frames.append(\n                PlotEstimate(\n                    p_Om=p_Om, p_s=p_s, Xhat_O=Xhat, chat=None, X_O=X_O, ax=ax\n                )\n            )\n\n    if animate:\n        ani = animation.ArtistAnimation(\n            fig, frames, interval=400, repeat=False\n        )\n\n        display(HTML(ani.to_jshtml()))\n        plt.close()\n\n    if X_O:\n        PrintResults(X_O, Xhat)\n\n    return Xhat, chat\n\n\np_Om, p_s, X_O = MakeRandomObjectModelAndScenePoints(num_model_points=20)\nIterativeClosestPoint(p_Om, p_s, X_O);","block_group":"6044a3e42ea84796a07cdb806947731f","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WLMLxAJJb1m2","colab_type":"text","cell_id":"f3b20926b0594359a4bd1f2f0a6c3f3b","deepnote_cell_type":"markdown"},"source":"Try increasing the standard deviation on yaw in the example above.  At some point, the performance can get pretty poor!\n\n# ICP with messy point clouds\n\nTry changing the amount of noise, the number of outliers, and/or the partial views.  There are not particularly good theorems here, but I hope that a little bit of play will get you a lot of intuition.","block_group":"b0884b5802cf45e898f4c99325b1ab75"},{"cell_type":"code","metadata":{"tags":[],"cell_id":"417394d8ded34906b2aee69ab82b9c30","deepnote_cell_type":"code"},"source":"p_Om, p_s, X_O = MakeRectangleModelAndScenePoints(\n    #    noise_std=0.2, # adds noise to each scene point (default is 0.0)\n    #    num_outliers=3, # adds random points from a uniform distribution\n    #    num_viewable_points=9, # only this number of model points appear in the scene points\n    yaw_O=0.2,  # object orientation (comment it out for random rotations)\n    p_O=[1, 2],  # object position (comment it out for random positions)\n)\nIterativeClosestPoint(p_Om, p_s, X_O);","block_group":"c2507b0f1df34396b7f56a370a071e5e","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"cell_id":"8e8e74192ecd4150ba928e86cd462de0","deepnote_cell_type":"markdown"},"source":"## Is least-squares the right cost function?\n\nHere is a particular setup that is interesting.  The configuration I've given you below results in ICP getting stuck in a local minima.  You will find that the system converges to this local minima from a wide variety of initial conditions.","block_group":"713079527c614c78bc490acb48baf35d"},{"cell_type":"code","metadata":{"cell_id":"f6ea392502a04492ae76f9f0958a71cf","deepnote_cell_type":"code"},"source":"p_Om, p_s, X_O = MakeRectangleModelAndScenePoints(\n    num_viewable_points=9,\n    yaw_O=0.2,\n    p_O=[1, 2],\n)\nIterativeClosestPoint(p_Om, p_s, X_O);","block_group":"fade3f4edfed48d7a33b7f173638f604","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"cell_id":"b90b28b0710c40cbb1265f407e90ed77","deepnote_cell_type":"markdown"},"source":"# Non-penetration constraints with nonlinear optimization","block_group":"7825f468a2db495e938b7a9b796a170f"},{"cell_type":"code","metadata":{"cell_id":"61a4e59ff00a430d9ea48346c0cefd28","deepnote_cell_type":"code"},"source":"def ConstrainedKnownCorrespondenceNonlinearOptimization(p_Om, p_s, chat):\n    \"\"\"This version adds a non-penetration constraint (x,y >= 0)\"\"\"\n\n    p_Omc = p_Om[:2, chat]\n    p_s = p_s[:2, :]\n    Ns = p_s.shape[1]\n\n    prog = MathematicalProgram()\n    p = prog.NewContinuousVariables(2, \"p\")\n    theta = prog.NewContinuousVariables(1, \"theta\")\n\n    def position_model_in_world(vars, i):\n        [p, theta] = np.split(vars, [2])\n        R = np.array(\n            [\n                [np.cos(theta[0]), -np.sin(theta[0])],\n                [np.sin(theta[0]), np.cos(theta[0])],\n            ]\n        )\n        p_Wmci = p + R @ p_Omc[:, i]\n        return p_Wmci\n\n    def squared_distance(vars, i):\n        p_Wmci = position_model_in_world(vars, i)\n        err = p_Wmci - p_s[:, i]\n        return err.dot(err)\n\n    for i in range(Ns):\n        # forall i, |p + R*p_Omi - p_si|Â²\n        prog.AddCost(\n            partial(squared_distance, i=i), np.concatenate([p[:], theta])\n        )\n        # forall i, p + R*p_Omi >= 0.\n        prog.AddConstraint(\n            partial(position_model_in_world, i=i),\n            vars=np.concatenate([p[:], theta]),\n            lb=[0, 0],\n            ub=[np.inf, np.inf],\n        )\n\n    result = Solve(prog)\n\n    theta_sol = result.GetSolution(theta[0])\n    Rsol = np.array(\n        [\n            [np.cos(theta_sol), -np.sin(theta_sol), 0],\n            [np.sin(theta_sol), np.cos(theta_sol), 0],\n            [0, 0, 1],\n        ]\n    )\n    psol = np.zeros(3)\n    psol[:2] = result.GetSolution(p)\n\n    return RigidTransform(RotationMatrix(Rsol), psol)\n\n\np_Om, p_s, X_O = MakeRectangleModelAndScenePoints(\n    yaw_O=0.2,\n    p_O=[1.5, 1.2],\n)\nc = range(p_Om.shape[1])  # perfect, known correspondences\nXhat_O = ConstrainedKnownCorrespondenceNonlinearOptimization(p_Om, p_s, c)\nPlotEstimate(p_Om=p_Om, p_s=p_s, Xhat_O=Xhat_O, chat=c, X_O=X_O)\nPrintResults(X_O, Xhat_O)\nplt.gca().plot([0, 0], [0, 2.5], \"g-\", linewidth=3)\nplt.gca().plot([0, 4], [0, 0], \"g-\", linewidth=3);","block_group":"7ba5685c0e4143c79137f3473e1ae6e9","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"cell_id":"b842320f4e7f4c2093c555b75bdfabbb","deepnote_cell_type":"markdown"},"source":"# Non-penetration (half-plane) constraints with convex optimization","block_group":"fa7be32f4ffa484e8f7b762c92af583f"},{"cell_type":"code","metadata":{"cell_id":"0b41ca96eee14959a32a27496ebf0b69","deepnote_cell_type":"code"},"source":"def ConstrainedKnownCorrespondenceConvexRelaxation(p_Om, p_s, chat):\n    \"\"\"This version adds a non-penetration constraint (x,y >= 0)\"\"\"\n\n    p_Omc = p_Om[:2, chat]\n    p_s = p_s[:2, :]\n    Ns = p_s.shape[1]\n\n    prog = MathematicalProgram()\n    [a, b] = prog.NewContinuousVariables(2)\n    # We use the slack variable as an upper bound on the cost of each point to make the objective linear.\n    slack = prog.NewContinuousVariables(Ns)\n    p = prog.NewContinuousVariables(2)\n    prog.AddBoundingBoxConstraint(0, 1, [a, b])  # This makes Csdp happier\n    R = np.array([[a, -b], [b, a]])\n    prog.AddLorentzConeConstraint([1.0, a, b])\n\n    # Note: Could do this more efficiently, exploiting trace.  But I'm keeping it simpler here.\n    prog.AddCost(np.sum(slack))\n    for i in range(Ns):\n        c = p + np.matmul(R, p_Omc[:, i]) - p_s[:, i]\n        # forall i, slack[i]^2 >= |c|^2\n        prog.AddLorentzConeConstraint([slack[i], c[0], c[1]])\n        # forall i, p + R*mi >= 0.\n        prog.AddConstraint(ge(p + np.matmul(R, p_Omc[:, i]), [0, 0]))\n\n    result = CsdpSolver().Solve(prog)\n\n    [a, b] = result.GetSolution([a, b])\n    Rsol = np.array([[a, -b, 0], [b, a, 0], [0, 0, 1]])\n    psol = np.zeros(3)\n    psol[:2] = result.GetSolution(p)\n\n    return RigidTransform(RotationMatrix(Rsol), psol)\n\n\np_Om, p_s, X_O = MakeRectangleModelAndScenePoints(\n    yaw_O=0.2,\n    p_O=[1.5, 1.2],\n)\nc = range(p_Om.shape[1])  # perfect, known correspondences\nXhat_O = ConstrainedKnownCorrespondenceConvexRelaxation(p_Om, p_s, c)\nPlotEstimate(p_Om=p_Om, p_s=p_s, Xhat_O=Xhat_O, chat=c, X_O=X_O)\nPrintResults(X_O, Xhat_O)\nplt.gca().plot([0, 0], [0, 2.5], \"g-\", linewidth=3)\nplt.gca().plot([0, 4], [0, 0], \"g-\", linewidth=3);","block_group":"91e5a261c3aa4bb5997afbaadb575499","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"6b7a6c5050e3444583ac64bcd5502c66","deepnote_cell_type":"code"},"source":"","block_group":"826c8dd398234272a42bb4db14880959","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=cc6340f5-374e-449a-a195-839a3cedec4a' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Robotic Manipulation - Geometric Pose Estimation.ipynb","provenance":[],"toc_visible":true,"collapsed_sections":[]},"vscode":{"interpreter":{"hash":"b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"}},"deepnote":{},"metadata":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}},"kernelspec":{"name":"python3","language":"python","display_name":"Python 3.10.6 64-bit"},"language_info":{"name":"python","version":"3.10.8 (main, Oct 13 2022, 09:48:40) [Clang 14.0.0 (clang-1400.0.29.102)]","mimetype":"text/x-python","file_extension":".py","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"nbconvert_exporter":"python"},"deepnote_notebook_id":"714616c0c5e446df9f379f60e271c766","deepnote_execution_queue":[]}}